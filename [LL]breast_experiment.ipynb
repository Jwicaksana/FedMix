{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef550afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "#################################\n",
    "TRAIN_RATIO = 0.8\n",
    "RS = 30448 # random state\n",
    "N_CHANNELS, N_CLASSES = 1, 1 \n",
    "bilinear = True\n",
    "BATCH_SIZE, EPOCHS = 16, 300\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CROP_SIZE = (224, 224)\n",
    "#########################################\n",
    "DIR = 'dataset/3datasets_segment_v2'\n",
    "CLIENTS = ['BUS', 'BUSIS', 'UDIAT']\n",
    "CLIENTS_2 = [cl +'_2' for cl in CLIENTS]\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "#####################################\n",
    "# add the classification segment ####\n",
    "#####################################\n",
    "DIR_CLASSIFICATION = DIR + '/BUS/classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "LR, WD, TH = 1e-3, 1e-5, 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb798488",
   "metadata": {},
   "source": [
    "## Training path - Testing path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_path = np.load('dict_path.npy', allow_pickle=True).item()\n",
    "breast_dataset = dict()\n",
    "for client in CLIENTS:\n",
    "    print(\"loading data from \", client)\n",
    "    dir_of_interest = consistent_path[client]\n",
    "    x_train = dir_of_interest['x_train']\n",
    "    x_test = dir_of_interest['x_test']\n",
    "    y_train = dir_of_interest['y_train']\n",
    "    y_test = dir_of_interest['y_test']\n",
    "    \n",
    "    # add normal images for bus # \n",
    "    DIR_INTEREST = DIR + '/'+ client \n",
    "    DATA_TYPE = ['original', 'GT']\n",
    "    if client == 'BUS':\n",
    "        for _,_, files in os.walk(DIR_INTEREST +'/classification/GT'):\n",
    "            selected = [f for f in files if f[:6] =='normal']\n",
    "            # update accordingly #\n",
    "            for data in DATA_TYPE:\n",
    "                tmp = [DIR_INTEREST + '/classification/' + data + '/' + f for f in selected]\n",
    "                if data == 'GT':\n",
    "                    y_train += tmp\n",
    "                else:\n",
    "                    x_train += tmp\n",
    "            print(x_train)\n",
    "    \n",
    "    # to measure the weight # \n",
    "    \n",
    "    breast_dataset[client+'_train']=Cancer(x_train, y_train, train=True,\\\n",
    "                                          IMAGE_SIZE=IMAGE_SIZE\\\n",
    "                                           , CROP_SIZE=CROP_SIZE)\n",
    "    \n",
    "    breast_dataset[client+'_test'] =Cancer(x_test, y_test, train=False,\\\n",
    "                                          IMAGE_SIZE=IMAGE_SIZE\\\n",
    "                                           , CROP_SIZE=CROP_SIZE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00d248",
   "metadata": {},
   "source": [
    "# storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clients, testing_clients = dict(), dict()\n",
    "training_clients_pl = dict()\n",
    "\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "    \n",
    "nets, optimizers = dict(), dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client in CLIENTS:\n",
    "    training_clients[client] = DataLoader(breast_dataset[client+'_train'], batch_size=16,\\\n",
    "                 shuffle=True, num_workers=8)\n",
    "    training_clients_pl[client] = DataLoader(breast_dataset[client+'_train'], batch_size=1, \\\n",
    "                shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(breast_dataset[client+'_test'], batch_size=1,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b519f",
   "metadata": {},
   "source": [
    "# local learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled', 'labeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63d1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_avg_acc, best_epoch_avg = 0, 0\n",
    "index = []\n",
    "\n",
    "for client in CLIENTS:\n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    index.append(epoch)\n",
    "    #### conduct training #####\n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        bbox_supervision = False\n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t)\n",
    "       \n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets[client], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(avg_acc, best_avg_acc)\n",
    "    plt.figure(0)\n",
    "    plt.plot(index, acc_train['UDIAT'], colors[0], label='UDIAT train')\n",
    "    plt.plot(index, acc_train['BUS'], colors[1], label='BUS  train')\n",
    "    plt.plot(index, acc_train['BUSIS'], colors[3], label='BUSIS  train')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(index, loss_train['UDIAT'], colors[0], label='UDIAT loss train')\n",
    "    plt.plot(index, loss_train['BUS'], colors[1], label='BUS  loss train')\n",
    "    plt.plot(index, loss_train['BUSIS'], colors[3], label='BUSIS  loss train')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(best_avg_acc, best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepLearning)",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
