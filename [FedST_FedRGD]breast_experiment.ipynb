{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf647e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "#################################\n",
    "N_CHANNELS, N_CLASSES = 1, 1 \n",
    "bilinear = True\n",
    "BATCH_SIZE, EPOCHS = 16, 300\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CROP_SIZE = (224, 224)\n",
    "#########################################\n",
    "DIR = 'dataset/breast'\n",
    "CLIENTS = ['BUS', 'BUSIS', 'UDIAT']\n",
    "CLIENTS_2 = [cl +'_2' for cl in CLIENTS]\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "#####################################\n",
    "# add the classification segment ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSISTENT_PATH = 'breast_5folds.npy'\n",
    "device = torch.device('cuda:0')\n",
    "LR, WD = 1e-3, 1e-4\n",
    "\n",
    "LAM, BETA, TH = 10, 1.5,0.9\n",
    "VERSION = 1\n",
    "WEIGHTS_CL = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00131510",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_EPOCH = 150\n",
    "CLIENTS_SUPERVISION = ['unlabeled', 'unlabeled', 'labeled']\n",
    "\n",
    "MODE = 'FedST' \n",
    "# MODE = 'FedRGD'\n",
    "\n",
    "CE_ = nn.BCELoss()\n",
    "WEIGHTS = [0.0, 0.0, 1.0]\n",
    "\n",
    "if MODE == 'FedST':\n",
    "    WEIGHTS_POSTWARMUP = [0.05, 0.05, 0.9] #put more weight to client with strong supervision\n",
    "else:\n",
    "    WEIGHTS_POSTWARMUP = [0.5/2., 0.5/2., 0.5] #random client, but effectively, put 1/2 trust to strongly supervised client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560533f",
   "metadata": {},
   "source": [
    "# load training-test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_path = np.load(CONSISTENT_PATH, allow_pickle=True).item()\n",
    "breast_dataset = dict()\n",
    "\n",
    "idx_ = 0\n",
    "denom_ = 0\n",
    "for client, sup in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "    dir_of_interest = consistent_path[client][VERSION]\n",
    "    x_train = dir_of_interest['x_train']\n",
    "    x_test = dir_of_interest['x_test']\n",
    "    y_train = dir_of_interest['y_train']\n",
    "    y_test = dir_of_interest['y_test']\n",
    "    '''\n",
    "    add normal images \n",
    "    '''\n",
    "    if sup == 'unlabeled':\n",
    "#     if client != 'UDIAT': \n",
    "        DATA_TYPE = ['original', 'GT']\n",
    "        for _,_, files in os.walk(DIR + '/'+ 'BUS' +'/classification/GT'):\n",
    "            selected = [f for f in files if f[:6] =='normal']\n",
    "            # update accordingly #\n",
    "            for data in DATA_TYPE:\n",
    "                tmp = [DIR + '/'+ 'BUS'  + '/classification/' + data + '/' + f for f in selected]\n",
    "                if data == 'GT':\n",
    "                    y_train += tmp\n",
    "                else:\n",
    "                    x_train += tmp\n",
    "    \n",
    "    print('full training data')\n",
    "    WEIGHTS_CL[idx_] = len(x_train)\n",
    "    denom_ += len(x_train)\n",
    "    idx_ += 1\n",
    "    breast_dataset[client+'_train']=Cancer(x_train, y_train, train=True,\\\n",
    "                                          IMAGE_SIZE=IMAGE_SIZE\\\n",
    "                                           , CROP_SIZE=CROP_SIZE)\n",
    "\n",
    "    \n",
    "    breast_dataset[client+'_test'] =Cancer(x_test, y_test, train=False,\\\n",
    "                                          IMAGE_SIZE=IMAGE_SIZE\\\n",
    "                                           , CROP_SIZE=CROP_SIZE)\n",
    "\n",
    "for idx_ in range(len(WEIGHTS_CL)):\n",
    "    WEIGHTS_CL[idx_] = WEIGHTS_CL[idx_]/denom_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967240b",
   "metadata": {},
   "source": [
    "# storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa76ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clients, testing_clients = dict(), dict()\n",
    "training_clients_pl = dict()\n",
    "\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "    \n",
    "nets, optimizers = dict(), dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client in CLIENTS:\n",
    "    training_clients[client] = DataLoader(breast_dataset[client+'_train'], batch_size=16,\\\n",
    "                 shuffle=True, num_workers=8)\n",
    "    training_clients_pl[client] = DataLoader(breast_dataset[client+'_train'], batch_size=1, \\\n",
    "                shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(breast_dataset[client+'_test'], batch_size=1,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52fbb5",
   "metadata": {},
   "source": [
    "## FedST or FedRGD: both require warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_avg_acc, best_epoch_avg = 0, 0\n",
    "index = []\n",
    "\n",
    "for client in CLIENTS:\n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "\n",
    "USE_UNLABELED_CLIENT = False\n",
    "for epoch in range(EPOCHS):\n",
    "    if epoch == WARMUP_EPOCH:\n",
    "        WEIGHTS = WEIGHTS_POSTWARMUP\n",
    "        USE_UNLABELED_CLIENT = True\n",
    "        \n",
    "    index.append(epoch)\n",
    "    \n",
    "    #################### copy fed model ###################\n",
    "    copy_fed(CLIENTS, nets, fed_name='global')\n",
    "    \n",
    "    #### conduct training #####\n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        if supervision_t == 'unlabeled':\n",
    "            if not USE_UNLABELED_CLIENT:\n",
    "                acc_train[client].append(0)\n",
    "                loss_train[client].append(0)\n",
    "                continue\n",
    "        \n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t, \\\n",
    "                                 warmup=True, CE_LOSS = CE_)\n",
    "        \n",
    "    aggr_fed(CLIENTS, WEIGHTS, nets)\n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets['global'], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(avg_acc, best_avg_acc)\n",
    "    plt.figure(0)\n",
    "    plt.plot(index, acc_train['UDIAT'], colors[0], label='UDIAT train')\n",
    "    plt.plot(index, acc_train['BUS'], colors[1], label='BUS  train')\n",
    "    plt.plot(index, acc_train['BUSIS'], colors[2], label='BUSIS  train')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(index, loss_train['UDIAT'], colors[0], label='UDIAT loss train')\n",
    "    plt.plot(index, loss_train['BUS'], colors[1], label='BUS  loss train')\n",
    "    plt.plot(index, loss_train['BUSIS'], colors[2], label='BUSIS  loss train')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(best_avg_acc, best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepLearning)",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
